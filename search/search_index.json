{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TinyBear","text":"<p>TinyBear is a lightweight utility library for working with data files and serialization formats in Python. It provides convenient tools for reading, writing, and validating CSV, XLS, JSON, TOML, YAML, and HTML files.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Simple interface for common data tasks</li> <li>Support for multiple data formats</li> <li>Easy data validation</li> <li>Designed for Python 3.9+</li> <li>Minimal dependencies</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<ul> <li>\ud83d\udcd6 Getting Started</li> <li>\u26a1 Usage</li> <li>\ud83e\udde9 API Reference</li> </ul> <p>For more details on available modules and methods, see the source code or contribute to extend the docs!</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#tinybearcsv_xls","title":"tinybear.csv_xls","text":""},{"location":"api/#append_empty_column_to_csv","title":"append_empty_column_to_csv","text":"<pre><code>def append_empty_column_to_csv(path_to_file: Path, name_of_new_column: str, delimiter: CSVDelimiter = \",\", custom_path_to_output_file: Optional[Path] = None) -&gt; None:\n</code></pre> <p>Adds empty column (as last column) to CSV file. Overwrites file, but optional output path can be specified to create a new file.</p> <p>Raises: - ValueError if column name already exists in file. - FileExistsError if custom output file is specified and already exists.</p>"},{"location":"api/#check_csv_for_malformed_rows","title":"check_csv_for_malformed_rows","text":"<pre><code>def check_csv_for_malformed_rows(path_to_file: Path) -&gt; None:\n</code></pre> <p>Checks whether all rows in CSV file have the same number of columns. Throws IndexError if they do not.</p>"},{"location":"api/#check_csv_for_repetitions_in_column","title":"check_csv_for_repetitions_in_column","text":"<pre><code>def check_csv_for_repetitions_in_column(path_to_file: Path, column_name: str) -&gt; None:\n</code></pre> <p>Throws ValueError if there are repetitions in given column of given file.</p>"},{"location":"api/#convert_xls_to_csv","title":"convert_xls_to_csv","text":"<pre><code>def convert_xls_to_csv(path_to_input_excel_file: Path, sheet_name: str, path_to_output_csv_file: Path, delimiter: CSVDelimiter = \",\", overwrite: bool = True) -&gt; None:\n</code></pre> <p>Converts sheet from Excel file to CSV format.</p>"},{"location":"api/#read_column_from_csv","title":"read_column_from_csv","text":"<pre><code>def read_column_from_csv(path_to_file: Path, column_name: str) -&gt; list[str]:\n</code></pre> <p>Reads one column from CSV file. Column name is taken from the top row. Raises KeyError if no such column exists.</p>"},{"location":"api/#read_dicts_from_csv","title":"read_dicts_from_csv","text":"<pre><code>def read_dicts_from_csv(path_to_file: Path, delimiter: CSVDelimiter = \",\") -&gt; list[dict[str, str]]:\n</code></pre> <p>Reads CSV as list of dictionaries (top row is considered key).</p>"},{"location":"api/#read_dict_from_2_csv_columns","title":"read_dict_from_2_csv_columns","text":"<pre><code>def read_dict_from_2_csv_columns(path_to_file: Path, key_col: str, val_col: str, delimiter: CSVDelimiter = \",\") -&gt; dict[str, str]:\n</code></pre> <p>Reads CSV and returns dict mapping keys from key_col to values from val_col.</p>"},{"location":"api/#read_dicts_from_xls","title":"read_dicts_from_xls","text":"<pre><code>def read_dicts_from_xls(path_to_file: Path, sheet_name: str) -&gt; list[dict[str, str]]:\n</code></pre> <p>Reads XLS sheet as list of dictionaries (top row as key).</p>"},{"location":"api/#read_plain_rows_from_csv","title":"read_plain_rows_from_csv","text":"<pre><code>def read_plain_rows_from_csv(path_to_file: Path, delimiter: CSVDelimiter = \",\", remove_1st_row: bool = False) -&gt; list[list[str]]:\n</code></pre> <p>Reads plain rows (list of lists) from CSV.</p>"},{"location":"api/#remove_rows_with_given_content_in_lookup_column","title":"remove_rows_with_given_content_in_lookup_column","text":"<pre><code>def remove_rows_with_given_content_in_lookup_column(rows: list[dict[str, str]], lookup_column: str, match_value: str) -&gt; tuple[list[dict[str, str]], tuple[int, ...]]:\n</code></pre> <p>Remove rows where lookup_column matches match_value. Returns (new list, indices of removed rows).</p>"},{"location":"api/#write_csv","title":"write_csv","text":"<pre><code>def write_csv(rows, path_to_file: Path, overwrite: bool, delimiter: CSVDelimiter) -&gt; None:\n</code></pre> <p>Writes rows (various formats) to CSV file. Adds header if writing dicts/NamedTuples.</p>"},{"location":"api/#tinybearjson_toml_yaml","title":"tinybear.json_toml_yaml","text":""},{"location":"api/#check_yaml_file","title":"check_yaml_file","text":"<pre><code>def check_yaml_file(path_to_file: Path, verbose: bool = True) -&gt; None:\n</code></pre> <p>Validates YAML file, throws if malformed or duplicate top-level keys are found.</p>"},{"location":"api/#read_json_toml_yaml","title":"read_json_toml_yaml","text":"<pre><code>def read_json_toml_yaml(path_to_file: Path) -&gt; Union[dict[str, Any], list[str]]:\n</code></pre> <p>Auto-detects file extension and deserializes JSON, TOML, or YAML to Python types.</p>"},{"location":"api/#tinybeartxt","title":"tinybear.txt","text":""},{"location":"api/#check_encoding_of_file","title":"check_encoding_of_file","text":"<pre><code>def check_encoding_of_file(file: Path) -&gt; str:\n</code></pre> <p>Check encoding (utf-8 or cp1251/ANSI); returns detected encoding.</p>"},{"location":"api/#read_non_empty_lines_from_txt_file","title":"read_non_empty_lines_from_txt_file","text":"<pre><code>def read_non_empty_lines_from_txt_file(path_to_file: Path) -&gt; list[str]:\n</code></pre> <p>Gets non-empty lines from TXT file as list.</p>"},{"location":"api/#read_plain_text_from_file","title":"read_plain_text_from_file","text":"<pre><code>def read_plain_text_from_file(path_to_file: Path) -&gt; str:\n</code></pre> <p>Reads plain text from file (utf-8 or cp1251 encoding).</p>"},{"location":"api/#remove_extra_space","title":"remove_extra_space","text":"<pre><code>def remove_extra_space(str_: str) -&gt; str:\n</code></pre> <p>Removes leading/trailing/multiple spaces in a string.</p>"},{"location":"api/#write_plain_text_to_file","title":"write_plain_text_to_file","text":"<pre><code>def write_plain_text_to_file(content: Union[str, list[str], tuple[str]], file: Path, overwrite: bool, newline_char: str = \"\\n\") -&gt; None:\n</code></pre> <p>Writes string or lines to text file. Optionally enforces overwrite/newlines.</p>"},{"location":"api/#move_line","title":"move_line","text":"<pre><code>def move_line(file: Path, line_number_to_cut: int, line_number_to_insert_before: Union[int, Literal[\"END\"]], output_file: Union[Path, None] = None) -&gt; None:\n</code></pre> <p>Moves a line in a text file to another position; saves to output file if given.</p>"},{"location":"api/#tinybearhtmlvalidate_html","title":"tinybear.html.validate_html","text":""},{"location":"api/#validate_html","title":"validate_html","text":"<pre><code>def validate_html(html: str, allowed_tags: Iterable[str] = (...), is_text_at_root_level_allowed: bool = False) -&gt; None:\n</code></pre> <p>Validate HTML string for allowed tags, structure, and correct entities. Raises ParsingError on errors.</p>"},{"location":"api/#tinybearhtmlfrom_docx","title":"tinybear.html.from_docx","text":""},{"location":"api/#convert_file_from_doc","title":"convert_file_from_doc","text":"<pre><code>def convert_file_from_doc(path_to_file: Path, output_dir: Path = DEFAULT_OUTPUT_DIR, style_map: str = DEFAULT_STYLE_MAP, print_html: bool = True) -&gt; Path:\n</code></pre> <p>Read from DOC(x), write to HTML file, return output path.</p>"},{"location":"api/#convert_all_docs","title":"convert_all_docs","text":"<pre><code>def convert_all_docs(input_dir: Path = DEFAULT_INPUT_DIR, output_dir: Path = DEFAULT_OUTPUT_DIR, print_html: bool = True) -&gt; None:\n</code></pre> <p>Convert all .DOC(x) files in a directory to HTML.</p>"},{"location":"api/#read_from_doc","title":"read_from_doc","text":"<pre><code>def read_from_doc(path_to_file: Path, style_map: str = DEFAULT_STYLE_MAP) -&gt; str:\n</code></pre> <p>Read binary DOCX file, return HTML string.</p>"},{"location":"api/#tinybearexceptions","title":"tinybear.exceptions","text":""},{"location":"api/#parsingerror","title":"ParsingError","text":"<pre><code>class ParsingError(Exception):\n    \"\"\"Base class for all parsing errors.\"\"\"\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":"<p>Welcome to TinyBear!</p> <p>This guide will help you quickly set up and start using TinyBear in your project.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>You can install TinyBear via pip:</p> <pre><code>pip install tinybear\n</code></pre> <p>Or clone the repository and install locally:</p> <pre><code>git clone https://github.com/lemontree210/tinybear\ncd tinybear\npip install .\n</code></pre>"},{"location":"getting_started/#requirements","title":"Requirements","text":"<p>TinyBear requires Python 3.9 or newer.</p> <p>Continue to the Usage section to learn how to use TinyBear in your workflow.</p>"},{"location":"usage/","title":"Usage","text":"<p>This section provides examples and instructions for using TinyBear.</p>"},{"location":"usage/#importing-modules","title":"Importing Modules","text":"<p>You can import TinyBear modules in your Python code:</p> <pre><code>from tinybear import csv_xls, json_toml_yaml\n</code></pre>"},{"location":"usage/#csvxls-operations","title":"CSV/XLS Operations","text":"<p>Read, write, and process CSV or XLS files using the <code>csv_xls</code> module. Example:</p> <pre><code>from tinybear import csv_xls\n# usage example here\n</code></pre>"},{"location":"usage/#json-toml-yaml-handling","title":"JSON, TOML, YAML Handling","text":"<p>Use the <code>json_toml_yaml</code> module for seamless serialization and deserialization:</p> <pre><code>from tinybear import json_toml_yaml\n# usage example here\n</code></pre> <p>For more detailed API information, refer to the source code or contribute to the docs!</p>"}]}